{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "MLP_Image_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdRb3QiLNYB1"
      },
      "source": [
        "\n",
        "\n",
        "In this second lab of the course, you will implement an image classifier using MLPs. We will use the MNIST dataset, which consists of greyscale handwritten digits. Each image is 28x28 pixels, you can see a sample below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIdK3c0FNYB4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "9c4cf156-b999-4c8b-b6be-c0f13ef55522"
      },
      "source": [
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML \n",
        "\n",
        "Image(url= \"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\", width=400, height=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\" width=\"400\" height=\"200\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZdl-PNSNYCB"
      },
      "source": [
        "Our goal is to build a neural network that can take one of these images and predict the digit in the image.\n",
        "\n",
        "Note: a big part of the following material is a personal wrap-up of [Facebook's Deep Learning Course in Udacity](https://www.udacity.com/course/deep-learning-pytorch--ud188). So all credit goes for them!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMizhwi3NYCD"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'  #To get figures with high quality!\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqsg788iNYCI"
      },
      "source": [
        "## Part I. Download MNIST with `torchvision`\n",
        "\n",
        "First up, we need to get our dataset. This is provided through the `torchvision` package. The [torchvision package](https://pytorch.org/docs/stable/torchvision/index.html) consists of popular datasets, model architectures, and common image transformations for computer vision.\n",
        "\n",
        "\n",
        "The code below will download the MNIST dataset, then create training and test datasets for us. Don't worry too much about the details here, you'll learn more about this later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1g0kg7nNYCK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "d8795603-cb49-45c9-eb61-be4a1268e489"
      },
      "source": [
        "### Run this cell\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "\n",
        "# Download and load the training  data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 8546538.50it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 122833.44it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2124342.64it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 47710.13it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFj5V4qwNYCP"
      },
      "source": [
        "We have the training data loaded into `trainloader` and we make that an iterator with `iter(trainloader)`. Later, we'll use this to loop through the dataset for training, like\n",
        "\n",
        "```python\n",
        "for image, label in trainloader:\n",
        "    ## do things with images and labels\n",
        "```\n",
        "\n",
        "You'll notice I created the `trainloader` with a batch size of 64, and `shuffle=True`. The batch size is the number of images we get in one iteration from the data loader and pass through our network, often called a *batch*. And `shuffle=True` tells it to **shuffle the dataset every time we start going through the data loader again**. But here I'm just grabbing the first batch so we can check out the data. We can see below that `images` is just a tensor with size `(64, 1, 28, 28)`. So, 64 images per batch, **1 color channel**, and 28x28 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "895kagALNYCR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "cf8cbb88-30c4-43df-c800-10dcf27429c5"
      },
      "source": [
        "dataiter = iter(trainloader)   #To iterate through the dataset\n",
        "\n",
        "images, labels = dataiter.next()\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LUWolp6NYCV"
      },
      "source": [
        "This is what one of the images looks like. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_DKAP8NNYCX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "26fe2cf2-debb-4bcb-e401-f7c5b7107910"
      },
      "source": [
        "plt.imshow(images[1].numpy().reshape([28,28]), cmap='Greys_r')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7efc609d21d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAHwCAYAAAC7cCafAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOiPcAaAzwh0AOiPcAaAzwh0AOvP/AVpvn+jJTy+4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 251,
              "height": 248
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-yp7FwKNYCb"
      },
      "source": [
        "## Part II. Train a multi-class Logistic Regressor\n",
        "\n",
        "Our first goal is to train a multi-class logistic regressor to evaluate how got it can do in both the training and the test sets. \n",
        "\n",
        "The following code is **almost identical** to the one you used for Lab 1 except for two small details:\n",
        "\n",
        "- We are training a LR classifier with 10 different outputs that implements a **softmax** non-linear function (instead of a binary LR with a sigmoid). \n",
        "\n",
        "- We are using the MNIST database loaded above.\n",
        "\n",
        "We first define the Multi-class Logistic Regressor class\n",
        "\n",
        "> **Exercise**: Complete the following code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3J1NHNoNYCc"
      },
      "source": [
        "class Multi_LR(nn.Module):\n",
        "    def __init__(self,dimx,nlabels): #Nlabels will be 10 in our case\n",
        "        super().__init__()\n",
        "        \n",
        "        self.output = nn.Linear(dimx,nlabels)\n",
        "    \n",
        "         \n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)     # NEW w.r.t Lab 1. dim is the dimension along which \n",
        "                                                #Softmax will be computed (so every slice along dim will sum to 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Pass the input tensor through each of our operations\n",
        "        x = self.output(x) #YOUR CODE HERE\n",
        "        x = self.logsoftmax(x) #YOUR CODE HERE\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IXh9CZFNYCi"
      },
      "source": [
        "Note that we use `nn.LogSoftmax` instead of `nn.Softmax()`. In many cases, softmax gives you probabilities which will often be very close to zero or one but floating-point numbers can't accurately represent values near zero or one ([read more here](https://docs.python.org/3/tutorial/floatingpoint.html)). It's usually best to avoid doing calculations with probabilities, typically we use log-probabilities.  The cross entropy loss is obtained by combining `nn.LogSoftmax` with the negative loss likelihood loss `nn.NLLLoss()`.\n",
        "\n",
        "Alternatively, we can use [`nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss). **This criterion combines `nn.LogSoftmax()` and `nn.NLLLoss()` in one single class.**\n",
        "\n",
        "This means we need to pass in the raw output of our network into the loss, not the output of the softmax function. This raw output is usually called the *logits* or *scores*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9Ir6PkpNYCj"
      },
      "source": [
        "Now we implement an extension to the class above (which inheritates from `Multi_LR`) that includes a training method.  One thing, note that MNIST images are of dimension $28\\times28=784$. To feed this image as the input to a `nn.Linear` layer, it has to be converted to a $784\\times 1$ input tensor. \n",
        "\n",
        "> **Exercise**: Complete the following code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS1Ouc7hNYCk"
      },
      "source": [
        "''' This class inherits from the `Multi_LR` class. So it has the same atributes\n",
        "and methods, and some others that we will add. \n",
        "'''\n",
        "class Multi_LR_extended(Multi_LR):\n",
        "    \n",
        "    def __init__(self,dimx,nlabels,epochs=100,lr=0.001):\n",
        "        \n",
        "        super().__init__(dimx,nlabels)  #To initialize `Multi_LR`!\n",
        "        \n",
        "        self.lr = lr #Learning Rate\n",
        "        \n",
        "        self.optim = optim.Adam(self.parameters(), self.lr)\n",
        "        \n",
        "        self.epochs = epochs\n",
        "        \n",
        "        self.criterion = nn.NLLLoss()               # NEW w.r.t Lab 1\n",
        "        \n",
        "        # A list to store the loss evolution along training\n",
        "        \n",
        "        self.loss_during_training = [] \n",
        "        \n",
        "    def train(self,trainloader):\n",
        "        \n",
        "        # Optimization Loop\n",
        "        \n",
        "        for e in range(int(self.epochs)):\n",
        "            \n",
        "            # Random data permutation at each epoch\n",
        "            \n",
        "            running_loss = 0.\n",
        "            \n",
        "            for images, labels in trainloader:              # NEW w.r.t Lab 1\n",
        "        \n",
        "                self.optim.zero_grad()  #TO RESET GRADIENTS!\n",
        "                print(images.view(images.shape[0], -1))\n",
        "                out = self.forward(images.view(images.shape[0], -1))\n",
        "                print(out)\n",
        "                print(labels)\n",
        "                break\n",
        "                loss = self.criterion(out,labels)\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                \n",
        "                #Your code here\n",
        "                loss.backward()\n",
        "                self.optim.step()\n",
        "                \n",
        "            self.loss_during_training.append(running_loss/len(trainloader))\n",
        "\n",
        "            if(e % 1 == 0): # Every 10 epochs\n",
        "\n",
        "                print(\"Training loss after %d epochs: %f\" \n",
        "                      %(e,self.loss_during_training[-1]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTX8SSQ6NYCp"
      },
      "source": [
        "Ok that was easy, wasn't it? Lets now train the multi-class LR and evaluate the performance in both the training and the test sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TXbYtRIyNYCq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "141f88f3-3e3e-48dd-b848-bec917380c56"
      },
      "source": [
        "my_LR = Multi_LR_extended(dimx=784,nlabels=10,epochs=5,lr=1e-3)\n",
        "\n",
        "my_LR.train(trainloader)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        ...,\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.]])\n",
            "tensor([[-1.4653, -2.3405, -2.9206, -3.0026, -2.4118, -2.5427, -2.4269, -2.7842,\n",
            "         -1.5484, -3.2655],\n",
            "        [-1.6120, -2.5922, -2.8697, -2.6476, -2.6100, -1.6824, -2.3857, -3.2164,\n",
            "         -1.7756, -3.2933],\n",
            "        [-2.2014, -2.3386, -2.8142, -2.8151, -2.6187, -1.8623, -1.8019, -2.8387,\n",
            "         -1.7022, -3.2424],\n",
            "        [-1.3581, -2.5605, -2.5062, -2.8866, -2.6086, -2.1170, -2.2832, -3.1803,\n",
            "         -1.8498, -3.3996],\n",
            "        [-1.2210, -2.5952, -3.0199, -2.7510, -3.3994, -2.2573, -1.9828, -3.2320,\n",
            "         -1.7011, -3.9075],\n",
            "        [-1.4559, -2.5094, -2.4613, -2.7820, -3.2530, -2.5066, -1.7193, -2.9918,\n",
            "         -1.8732, -3.3521],\n",
            "        [-2.5458, -2.8985, -2.7605, -2.7195, -3.2804, -1.3424, -2.1811, -2.6984,\n",
            "         -1.5089, -3.2941],\n",
            "        [-1.2833, -2.8828, -2.5295, -3.1219, -2.7127, -2.1448, -2.3745, -2.4706,\n",
            "         -1.9252, -3.3179],\n",
            "        [-1.2739, -2.3538, -2.7740, -2.7832, -2.4164, -1.9919, -2.8044, -2.6702,\n",
            "         -2.1466, -3.5521],\n",
            "        [-1.9706, -2.0568, -2.4215, -2.8281, -3.0642, -2.2176, -1.6635, -2.7928,\n",
            "         -2.0662, -2.9587],\n",
            "        [-1.4542, -2.4999, -2.4691, -2.8457, -2.6869, -2.7035, -1.9291, -2.3866,\n",
            "         -2.1857, -2.8667],\n",
            "        [-1.4085, -2.7063, -3.1932, -2.8037, -3.0061, -2.3210, -2.1867, -3.3364,\n",
            "         -1.2997, -3.9663],\n",
            "        [-1.3006, -2.7699, -2.4901, -2.9189, -2.5421, -2.4176, -2.1427, -2.6867,\n",
            "         -1.8933, -3.7201],\n",
            "        [-1.3761, -2.4888, -3.5099, -2.6428, -3.0731, -2.3162, -2.0461, -3.1289,\n",
            "         -1.5024, -3.7789],\n",
            "        [-1.4761, -1.8968, -2.6581, -2.9608, -2.5550, -2.3428, -2.2636, -2.7169,\n",
            "         -2.1467, -3.2474],\n",
            "        [-1.3976, -2.8170, -3.1033, -2.7997, -2.9924, -2.3534, -2.0729, -3.0452,\n",
            "         -1.3942, -3.8804],\n",
            "        [-2.0175, -2.6595, -2.4151, -2.8077, -2.9642, -2.1168, -1.5730, -2.6784,\n",
            "         -1.8548, -3.1532],\n",
            "        [-2.0985, -2.4662, -2.6342, -2.5829, -2.5172, -1.8079, -2.2139, -2.8932,\n",
            "         -1.6506, -3.1277],\n",
            "        [-1.4429, -3.2926, -2.4568, -2.9294, -2.7006, -2.1495, -1.9906, -2.8209,\n",
            "         -1.7793, -3.2485],\n",
            "        [-1.4031, -2.4207, -3.1979, -2.5240, -3.2168, -2.1635, -1.8360, -2.6697,\n",
            "         -2.0208, -3.5737],\n",
            "        [-2.0728, -2.4792, -2.8189, -2.7070, -2.7074, -1.3449, -2.2884, -2.7526,\n",
            "         -2.0683, -3.0996],\n",
            "        [-1.7231, -2.2076, -2.5557, -2.5641, -2.7309, -2.1498, -1.9773, -2.9246,\n",
            "         -1.9600, -3.1644],\n",
            "        [-1.7729, -2.4891, -2.4810, -2.6474, -3.0863, -2.0239, -2.1876, -2.5306,\n",
            "         -1.6293, -3.6115],\n",
            "        [-2.0151, -2.5336, -2.7414, -2.7056, -2.4932, -1.5273, -2.4400, -3.1235,\n",
            "         -1.7103, -3.1177],\n",
            "        [-1.4231, -2.2413, -2.4534, -2.9815, -2.7209, -2.3993, -2.3464, -3.2670,\n",
            "         -1.6472, -3.4120],\n",
            "        [-1.4179, -2.7884, -2.7340, -2.7916, -2.7485, -2.1226, -2.0097, -2.9571,\n",
            "         -1.8612, -3.1066],\n",
            "        [-1.3130, -2.4932, -2.5430, -3.2285, -2.4379, -2.3322, -2.6065, -2.5037,\n",
            "         -1.8691, -3.3287],\n",
            "        [-1.4832, -2.1043, -2.3571, -2.7568, -2.9901, -2.3248, -2.4334, -3.3358,\n",
            "         -1.8057, -2.8611],\n",
            "        [-2.0406, -2.4222, -2.3091, -2.8925, -3.0138, -1.9582, -1.7630, -3.1055,\n",
            "         -1.7271, -3.1656],\n",
            "        [-2.3911, -2.7382, -3.2091, -2.6806, -3.0646, -1.2876, -1.8378, -2.4946,\n",
            "         -1.9627, -3.5034],\n",
            "        [-1.2489, -2.0252, -2.5672, -2.9219, -2.9945, -3.0932, -2.2869, -2.4575,\n",
            "         -1.9516, -3.6518],\n",
            "        [-1.3638, -2.7991, -2.9449, -2.4143, -2.4811, -1.9620, -2.5649, -2.6725,\n",
            "         -1.9228, -3.6902],\n",
            "        [-1.6434, -2.2749, -2.7292, -2.8242, -2.7943, -1.9602, -2.2303, -2.6583,\n",
            "         -1.8426, -3.1872],\n",
            "        [-1.2976, -2.3633, -2.4775, -3.0016, -2.6949, -2.6039, -2.5352, -2.9379,\n",
            "         -1.6697, -3.2973],\n",
            "        [-1.6907, -2.8375, -2.6992, -2.5401, -3.0265, -1.7430, -1.7675, -2.4563,\n",
            "         -2.3745, -3.2733],\n",
            "        [-1.6317, -2.2085, -2.2649, -2.3692, -3.2469, -2.2894, -2.0258, -2.6564,\n",
            "         -2.3298, -2.8556],\n",
            "        [-2.0939, -2.5025, -2.1203, -2.7873, -2.8303, -1.7021, -2.1816, -2.6530,\n",
            "         -1.9448, -3.0851],\n",
            "        [-1.6106, -2.4943, -2.9380, -2.7614, -3.1547, -1.7194, -1.9656, -3.2584,\n",
            "         -1.7808, -3.4221],\n",
            "        [-1.4211, -2.2404, -3.1326, -2.8336, -2.3769, -2.3543, -2.1839, -2.8389,\n",
            "         -1.8143, -3.5796],\n",
            "        [-2.0432, -2.5750, -2.7492, -2.4798, -2.9806, -1.6974, -1.8338, -2.9751,\n",
            "         -1.7395, -3.6452],\n",
            "        [-1.3104, -2.4803, -2.4612, -3.0675, -2.9077, -2.4887, -1.9969, -3.2693,\n",
            "         -1.7134, -3.7700],\n",
            "        [-1.1304, -3.0770, -2.2399, -3.1371, -3.1519, -2.7433, -2.4255, -2.1125,\n",
            "         -1.9968, -3.5456],\n",
            "        [-1.8156, -2.5125, -2.5751, -2.6632, -2.7094, -1.9630, -1.9078, -2.5482,\n",
            "         -2.0306, -3.0916],\n",
            "        [-1.4114, -2.5324, -3.0185, -3.3379, -3.0667, -2.3989, -2.0324, -2.6750,\n",
            "         -1.5334, -3.2387],\n",
            "        [-1.8726, -2.5031, -2.7436, -3.2129, -2.9010, -2.1128, -1.6585, -2.6998,\n",
            "         -1.6186, -3.5694],\n",
            "        [-1.6546, -1.7820, -2.3700, -2.8084, -2.6047, -2.4405, -2.6206, -2.6170,\n",
            "         -2.0162, -3.0630],\n",
            "        [-1.6527, -2.3569, -2.4417, -2.4617, -2.5754, -2.4216, -2.2636, -2.8618,\n",
            "         -1.7624, -3.1287],\n",
            "        [-1.2437, -3.0618, -2.4608, -3.0780, -3.0024, -2.4723, -2.2449, -2.8236,\n",
            "         -1.6657, -3.1010],\n",
            "        [-1.9966, -2.3532, -2.2183, -2.7524, -2.6118, -1.8690, -2.3075, -2.6389,\n",
            "         -1.8540, -3.1860],\n",
            "        [-1.9152, -2.6910, -2.7021, -2.7874, -3.0314, -2.2595, -1.5510, -2.6129,\n",
            "         -1.7870, -2.9807],\n",
            "        [-1.3935, -2.6068, -2.9752, -2.7639, -2.6989, -1.9113, -2.4819, -3.2749,\n",
            "         -1.6404, -3.3970],\n",
            "        [-1.9141, -2.5978, -2.5361, -2.6270, -2.5360, -1.7821, -2.1039, -2.8508,\n",
            "         -1.8253, -3.2648],\n",
            "        [-1.3454, -2.4099, -2.7613, -3.1086, -2.6759, -2.7522, -2.1229, -3.0564,\n",
            "         -1.5725, -3.3530],\n",
            "        [-1.5740, -2.2312, -2.5238, -3.0235, -3.0620, -2.2777, -2.1362, -2.5858,\n",
            "         -1.7182, -3.3674],\n",
            "        [-1.1240, -2.1821, -2.7862, -2.6494, -3.4608, -2.6996, -2.3027, -2.9944,\n",
            "         -1.9109, -3.4047],\n",
            "        [-1.3762, -2.4992, -2.8060, -2.8322, -3.1144, -2.1617, -2.0959, -2.6666,\n",
            "         -1.8676, -3.2309],\n",
            "        [-1.6536, -2.4182, -2.7480, -2.9762, -2.6323, -1.9654, -1.9978, -2.8932,\n",
            "         -1.8167, -3.2467],\n",
            "        [-1.1614, -2.3789, -2.7736, -3.7310, -2.6486, -2.9320, -2.5697, -3.2432,\n",
            "         -1.4522, -3.3755],\n",
            "        [-1.6867, -2.4466, -2.8654, -2.4298, -2.4832, -1.9238, -2.2111, -2.7218,\n",
            "         -1.9722, -3.2376],\n",
            "        [-1.5779, -2.3899, -3.3217, -2.3794, -3.2347, -2.2461, -2.0285, -2.4585,\n",
            "         -1.6428, -4.0428],\n",
            "        [-1.7540, -2.2046, -2.5768, -2.5558, -2.7445, -2.0275, -2.2092, -2.6574,\n",
            "         -1.9940, -2.9768],\n",
            "        [-1.4431, -2.3100, -2.3455, -2.7787, -2.5745, -2.6674, -2.5071, -2.7627,\n",
            "         -1.7686, -3.0831],\n",
            "        [-1.7315, -2.5615, -2.8592, -2.5931, -3.0697, -1.4104, -2.3178, -2.8532,\n",
            "         -2.1118, -3.0779],\n",
            "        [-1.9154, -2.3597, -2.8171, -2.7583, -2.8201, -2.0568, -1.6595, -2.3844,\n",
            "         -2.0238, -3.4083]], grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([8, 1, 7, 3, 4, 2, 3, 5, 0, 7, 9, 9, 8, 9, 2, 9, 7, 1, 3, 6, 7, 2, 3, 1,\n",
            "        9, 4, 5, 6, 9, 3, 8, 9, 3, 0, 5, 9, 1, 6, 5, 3, 3, 5, 7, 5, 5, 2, 2, 5,\n",
            "        1, 7, 1, 1, 9, 0, 6, 6, 3, 0, 6, 8, 3, 3, 7, 2])\n",
            "Training loss after 0 epochs: 0.000000\n",
            "tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        ...,\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.]])\n",
            "tensor([[-1.5069, -2.5260, -2.2783, -2.9747, -2.5789, -2.2196, -2.2937, -3.1393,\n",
            "         -1.7216, -3.2858],\n",
            "        [-1.5914, -2.7253, -2.9407, -2.5951, -3.2263, -2.0930, -1.5390, -2.8970,\n",
            "         -1.8617, -4.1896],\n",
            "        [-1.6685, -3.2042, -2.7041, -2.8996, -2.7485, -1.2930, -2.5532, -3.0270,\n",
            "         -1.8635, -3.5395],\n",
            "        [-1.4401, -2.5270, -2.6352, -2.5240, -3.1332, -2.6702, -2.7423, -3.4187,\n",
            "         -1.2100, -3.7648],\n",
            "        [-1.6329, -2.5422, -2.7800, -2.5703, -2.9121, -2.2653, -1.5735, -2.6816,\n",
            "         -2.1643, -3.2539],\n",
            "        [-1.7685, -2.3726, -2.3651, -2.7492, -2.7081, -2.0058, -2.0672, -3.3889,\n",
            "         -1.6664, -3.5812],\n",
            "        [-1.4495, -2.6386, -2.2198, -3.3113, -2.5099, -2.5135, -2.4899, -3.5968,\n",
            "         -1.3886, -3.6212],\n",
            "        [-1.4749, -2.5138, -2.5646, -2.9940, -3.1228, -2.5821, -1.9564, -2.7360,\n",
            "         -1.5967, -3.3586],\n",
            "        [-1.6938, -2.6267, -2.6667, -2.7592, -3.2031, -2.1458, -1.7667, -3.0034,\n",
            "         -1.7133, -2.9441],\n",
            "        [-2.0241, -2.3416, -2.4500, -2.8339, -2.5367, -2.0249, -2.3743, -2.7690,\n",
            "         -1.4830, -3.4197],\n",
            "        [-1.9115, -2.6327, -2.6295, -2.9658, -2.9693, -1.7611, -1.6701, -2.7564,\n",
            "         -1.9486, -3.2385],\n",
            "        [-1.7392, -1.9624, -2.7655, -2.6107, -2.2611, -2.8237, -2.2405, -2.7273,\n",
            "         -1.7339, -3.3414],\n",
            "        [-1.4963, -2.6893, -2.8065, -2.6030, -3.2170, -2.3739, -2.2210, -2.2043,\n",
            "         -1.6216, -3.7282],\n",
            "        [-1.5979, -2.4484, -2.7507, -2.5782, -2.8503, -2.0388, -2.2182, -2.7190,\n",
            "         -1.7047, -3.6164],\n",
            "        [-2.1088, -2.3722, -2.3401, -2.8014, -2.6035, -1.8304, -2.2635, -2.5353,\n",
            "         -1.7519, -3.2898],\n",
            "        [-1.7941, -2.9793, -2.7430, -2.5731, -3.3354, -1.5356, -2.1373, -2.8170,\n",
            "         -1.7780, -3.1112],\n",
            "        [-2.1305, -2.4447, -2.7294, -2.6600, -2.9008, -2.3115, -1.8561, -2.6847,\n",
            "         -1.4901, -2.8952],\n",
            "        [-1.7819, -2.7744, -2.5565, -2.8781, -3.1690, -1.8114, -1.6962, -2.8546,\n",
            "         -1.8700, -3.3546],\n",
            "        [-1.3071, -2.6664, -2.9080, -2.6874, -2.6965, -1.9732, -2.3225, -3.1204,\n",
            "         -1.8614, -3.4055],\n",
            "        [-1.8672, -2.5851, -2.8948, -2.3125, -2.3449, -2.1875, -2.0458, -2.7260,\n",
            "         -1.7185, -3.3937],\n",
            "        [-1.8573, -2.4673, -2.6509, -2.4910, -2.4490, -2.3014, -2.2048, -2.7987,\n",
            "         -1.5962, -3.0937],\n",
            "        [-1.9145, -2.5822, -3.3004, -2.3659, -2.8563, -2.1071, -1.6859, -2.6262,\n",
            "         -1.7176, -3.5050],\n",
            "        [-1.8149, -2.6401, -3.2384, -2.7206, -2.6157, -2.2411, -1.8144, -3.1507,\n",
            "         -1.4006, -3.5383],\n",
            "        [-1.2877, -2.5244, -2.5861, -2.7644, -2.8331, -2.5936, -2.3924, -3.2379,\n",
            "         -1.5762, -3.3623],\n",
            "        [-1.2995, -2.8654, -2.5973, -2.8359, -2.7696, -2.4909, -2.4887, -2.0973,\n",
            "         -1.8559, -3.5200],\n",
            "        [-1.2063, -2.3040, -2.4169, -3.2174, -3.0106, -2.2574, -2.5129, -3.6442,\n",
            "         -1.7246, -3.4334],\n",
            "        [-1.6197, -2.5629, -2.7684, -3.1350, -2.6241, -2.1537, -2.2266, -2.4370,\n",
            "         -1.7085, -2.9247],\n",
            "        [-1.3988, -2.5742, -3.1377, -2.8797, -3.0346, -2.4514, -1.7950, -2.9876,\n",
            "         -1.5855, -3.8302],\n",
            "        [-1.5532, -2.6319, -2.9047, -2.8137, -3.2779, -1.4607, -2.3386, -3.3630,\n",
            "         -1.7648, -3.5182],\n",
            "        [-1.3993, -2.6434, -2.8793, -2.7510, -2.7546, -1.8990, -2.3637, -3.1538,\n",
            "         -1.7207, -3.4110],\n",
            "        [-1.8828, -2.8076, -3.1309, -2.3958, -2.7886, -1.8672, -1.9037, -3.4233,\n",
            "         -1.4696, -3.6884],\n",
            "        [-1.7610, -2.2806, -2.4758, -2.8150, -2.9835, -2.3738, -2.3619, -2.8611,\n",
            "         -1.3613, -3.4935],\n",
            "        [-1.5745, -2.2210, -2.9982, -2.6158, -2.7211, -2.4475, -2.1235, -2.6215,\n",
            "         -1.8010, -2.9632],\n",
            "        [-2.1544, -2.3051, -2.5536, -2.8460, -2.2723, -1.8732, -1.8980, -2.9408,\n",
            "         -1.9302, -3.1261],\n",
            "        [-2.4576, -2.5351, -2.5971, -3.2330, -2.9527, -1.9540, -1.2331, -2.5711,\n",
            "         -2.2936, -2.8385],\n",
            "        [-1.4550, -2.1457, -2.7577, -2.9134, -2.4900, -2.2263, -2.3338, -2.9771,\n",
            "         -1.8050, -3.5509],\n",
            "        [-1.9581, -2.5604, -2.6911, -2.5220, -2.5148, -1.5744, -2.4497, -3.0837,\n",
            "         -1.7666, -3.1594],\n",
            "        [-1.8710, -2.4351, -2.4950, -2.7766, -2.4315, -1.9471, -2.3416, -3.3219,\n",
            "         -1.5461, -3.2766],\n",
            "        [-1.3167, -2.1922, -2.9358, -3.3384, -2.8511, -2.6436, -1.9581, -3.0533,\n",
            "         -1.6776, -3.5868],\n",
            "        [-1.7007, -2.5217, -2.6686, -2.3669, -2.2975, -1.9601, -2.2970, -3.0563,\n",
            "         -1.8760, -3.4480],\n",
            "        [-1.7552, -1.9877, -2.4297, -2.6681, -2.8452, -2.1449, -2.2096, -2.8635,\n",
            "         -1.8497, -3.4004],\n",
            "        [-1.7549, -2.3977, -2.7730, -2.7191, -2.9905, -2.2850, -1.9239, -3.0544,\n",
            "         -1.4597, -3.4993],\n",
            "        [-1.1543, -2.1179, -2.7863, -3.2008, -2.4252, -2.7880, -2.8739, -2.9441,\n",
            "         -1.7219, -3.7216],\n",
            "        [-1.4834, -2.3057, -3.2914, -3.2037, -3.1171, -2.4350, -1.5434, -2.6417,\n",
            "         -1.9271, -3.4028],\n",
            "        [-1.9615, -2.7765, -2.6155, -2.6225, -2.6735, -2.5250, -2.0262, -3.3258,\n",
            "         -1.1910, -3.4874],\n",
            "        [-1.9409, -2.6210, -2.5225, -2.5268, -2.5347, -1.8196, -2.1098, -3.0955,\n",
            "         -1.7804, -3.0559],\n",
            "        [-1.6293, -2.6281, -2.9771, -2.7587, -2.9083, -1.6518, -2.0234, -2.9486,\n",
            "         -1.8652, -3.4532],\n",
            "        [-1.2750, -1.9939, -2.7337, -3.2101, -2.5023, -3.2155, -2.3389, -3.4027,\n",
            "         -1.5854, -3.7956],\n",
            "        [-1.8897, -2.4109, -2.4194, -3.0727, -2.7892, -1.8201, -1.8980, -2.7603,\n",
            "         -1.8897, -3.3199],\n",
            "        [-1.4635, -2.1291, -2.7593, -3.0401, -2.8274, -2.5428, -2.0876, -3.1267,\n",
            "         -1.6049, -3.4450],\n",
            "        [-1.9917, -2.5929, -2.5652, -2.4100, -2.4576, -1.8473, -2.2815, -2.9814,\n",
            "         -1.7117, -3.0944],\n",
            "        [-1.5277, -2.4696, -2.7383, -2.4647, -3.0753, -2.3608, -2.3073, -3.2429,\n",
            "         -1.4149, -3.6273],\n",
            "        [-1.9609, -2.5024, -2.2652, -2.6095, -2.6739, -2.1182, -2.3110, -2.4485,\n",
            "         -1.6793, -3.2528],\n",
            "        [-1.7411, -2.4948, -2.8863, -2.4676, -2.2798, -2.2156, -2.0051, -3.1478,\n",
            "         -1.6670, -3.7383],\n",
            "        [-1.4985, -2.1877, -2.6638, -3.1652, -2.6771, -2.4000, -2.2320, -3.3351,\n",
            "         -1.5397, -3.3345],\n",
            "        [-1.4344, -2.0525, -2.4745, -2.9337, -3.2922, -2.5487, -1.9963, -2.9529,\n",
            "         -1.9327, -3.0417],\n",
            "        [-1.1028, -2.6652, -3.0248, -2.5567, -3.1771, -2.4399, -2.1671, -2.8313,\n",
            "         -1.8862, -3.9967],\n",
            "        [-2.0367, -2.5404, -2.4200, -2.4542, -2.4055, -1.8053, -2.2374, -2.8932,\n",
            "         -1.8432, -3.1998],\n",
            "        [-1.7188, -2.8241, -2.7685, -2.5967, -2.9610, -2.1662, -1.7794, -2.4892,\n",
            "         -1.7462, -3.4568],\n",
            "        [-1.9135, -2.0074, -2.7140, -2.2954, -2.8196, -2.4103, -2.2985, -2.9592,\n",
            "         -1.5231, -3.4613],\n",
            "        [-2.3661, -3.0314, -3.0406, -2.2655, -3.1413, -1.8823, -1.7762, -3.1914,\n",
            "         -1.2794, -3.8054],\n",
            "        [-1.3030, -2.1414, -2.9501, -2.9065, -3.0870, -2.3654, -2.3777, -3.0322,\n",
            "         -1.6052, -3.7979],\n",
            "        [-1.8099, -2.6116, -2.5574, -2.3854, -2.3874, -1.9780, -2.1794, -3.0843,\n",
            "         -1.7892, -3.2923],\n",
            "        [-2.1577, -2.4940, -2.3661, -3.0330, -2.8777, -2.2653, -1.2162, -2.9579,\n",
            "         -2.2563, -3.0634]], grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([0, 6, 7, 8, 8, 0, 0, 3, 7, 6, 7, 8, 8, 5, 1, 7, 9, 5, 1, 8, 1, 9, 9, 4,\n",
            "        5, 0, 8, 9, 7, 1, 3, 0, 6, 7, 2, 2, 1, 9, 0, 4, 3, 0, 0, 5, 3, 1, 5, 8,\n",
            "        7, 9, 1, 8, 1, 4, 0, 2, 4, 1, 2, 2, 3, 0, 4, 7])\n",
            "Training loss after 1 epochs: 0.000000\n",
            "tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        ...,\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.]])\n",
            "tensor([[-1.2402, -2.7891, -3.1356, -2.9442, -2.8086, -1.9035, -2.0923, -3.1647,\n",
            "         -1.8779, -3.6805],\n",
            "        [-1.8628, -2.8009, -2.9213, -2.3352, -3.0351, -1.9188, -1.6788, -2.3079,\n",
            "         -2.0910, -3.5446],\n",
            "        [-1.2303, -2.5496, -2.5860, -2.7555, -2.9509, -2.2795, -2.8660, -3.4725,\n",
            "         -1.4736, -3.9581],\n",
            "        [-1.7601, -2.5697, -2.6846, -2.9976, -2.6927, -2.1421, -1.8189, -2.7926,\n",
            "         -1.6144, -3.6618],\n",
            "        [-1.7193, -2.4258, -2.6272, -2.5480, -2.9996, -2.0479, -2.3110, -2.7863,\n",
            "         -1.5585, -3.4483],\n",
            "        [-1.0451, -3.0037, -3.3525, -2.4804, -2.9441, -2.1329, -2.5485, -2.4397,\n",
            "         -2.0903, -3.9199],\n",
            "        [-1.8083, -2.4631, -2.9446, -2.4781, -2.7833, -1.7055, -1.9201, -2.6481,\n",
            "         -2.1940, -3.1697],\n",
            "        [-1.8664, -2.5700, -2.5335, -2.4585, -2.5760, -1.8211, -2.1827, -3.0479,\n",
            "         -1.8057, -3.1854],\n",
            "        [-2.4584, -2.6768, -2.6172, -3.1508, -3.4868, -1.8924, -1.0843, -2.9990,\n",
            "         -2.1592, -3.0985],\n",
            "        [-1.9776, -2.6591, -2.3295, -2.6778, -2.5973, -1.9015, -2.1156, -2.5917,\n",
            "         -1.8432, -3.0376],\n",
            "        [-1.5901, -2.3085, -2.9314, -3.1115, -2.6356, -2.0927, -1.8839, -3.0485,\n",
            "         -1.8224, -3.1530],\n",
            "        [-1.5849, -2.6177, -2.6842, -2.9427, -2.9549, -2.3833, -1.9840, -2.8258,\n",
            "         -1.5088, -3.2500],\n",
            "        [-1.9713, -2.9318, -2.5820, -2.8198, -3.0344, -1.6030, -1.7426, -2.8725,\n",
            "         -1.7937, -3.6959],\n",
            "        [-1.5741, -2.5228, -2.7926, -2.4960, -2.3853, -1.9453, -2.7960, -2.6021,\n",
            "         -1.7972, -3.4130],\n",
            "        [-1.7773, -2.2103, -2.4737, -2.8459, -2.6760, -2.2123, -2.2969, -2.5781,\n",
            "         -1.7299, -3.0620],\n",
            "        [-1.6902, -2.3801, -2.6169, -2.6288, -2.7323, -2.1023, -1.9905, -3.1848,\n",
            "         -1.6702, -3.7175],\n",
            "        [-2.3154, -2.3220, -2.8362, -2.8077, -2.4488, -1.3939, -2.2705, -2.8703,\n",
            "         -1.8644, -3.3591],\n",
            "        [-1.4280, -2.4185, -2.5988, -2.7723, -3.1202, -2.3475, -2.3258, -3.2694,\n",
            "         -1.5223, -3.2051],\n",
            "        [-1.2515, -2.0617, -3.0828, -3.0734, -2.9042, -2.8103, -1.9540, -2.9598,\n",
            "         -1.8249, -3.6952],\n",
            "        [-1.2690, -2.5549, -2.5351, -2.8505, -2.7628, -3.0236, -2.8070, -2.7526,\n",
            "         -1.4503, -3.3887],\n",
            "        [-1.4144, -2.4381, -2.7141, -2.6889, -2.5643, -2.5173, -1.9406, -3.0531,\n",
            "         -1.8454, -3.5425],\n",
            "        [-2.1564, -2.4458, -2.7579, -2.6420, -2.4200, -1.7085, -1.8963, -2.8624,\n",
            "         -1.9674, -3.0828],\n",
            "        [-1.3872, -2.3704, -2.6860, -2.7044, -2.6670, -2.1889, -2.7147, -2.9774,\n",
            "         -1.6251, -3.6425],\n",
            "        [-1.4897, -2.5307, -2.3872, -2.6720, -3.3668, -2.1607, -2.0509, -2.7463,\n",
            "         -1.8112, -3.5764],\n",
            "        [-1.7824, -2.4716, -2.6410, -2.6787, -3.0462, -2.5075, -1.6096, -2.5351,\n",
            "         -1.8777, -3.0745],\n",
            "        [-1.5389, -2.3639, -2.6864, -2.9318, -2.9731, -2.4479, -1.8280, -2.9793,\n",
            "         -1.7269, -3.1495],\n",
            "        [-1.5431, -3.0298, -3.0908, -2.6887, -3.0389, -2.3612, -2.1692, -2.7616,\n",
            "         -1.2580, -3.8796],\n",
            "        [-2.1431, -2.7158, -3.2750, -2.9974, -2.8235, -1.2793, -1.9289, -3.2284,\n",
            "         -1.7361, -3.5046],\n",
            "        [-2.6521, -2.5035, -3.0659, -2.6172, -3.3350, -1.2001, -1.8060, -3.1798,\n",
            "         -1.8340, -3.6635],\n",
            "        [-1.8441, -2.8715, -2.5829, -2.7188, -2.9168, -1.6550, -1.8885, -2.8510,\n",
            "         -1.8658, -3.3618],\n",
            "        [-1.5959, -2.4428, -3.2631, -2.7522, -2.6938, -2.1158, -2.0748, -2.8465,\n",
            "         -1.5667, -3.5830],\n",
            "        [-1.7243, -2.4279, -2.6851, -2.3527, -2.7694, -1.7297, -2.1347, -2.8127,\n",
            "         -2.0436, -3.8066],\n",
            "        [-1.6169, -2.1470, -2.6118, -2.6824, -3.1012, -2.6453, -2.0707, -2.6606,\n",
            "         -1.6562, -3.2186],\n",
            "        [-1.6293, -1.9919, -2.4700, -2.7441, -3.2164, -3.2845, -1.8319, -2.4788,\n",
            "         -1.8766, -3.1234],\n",
            "        [-1.7168, -2.4839, -2.7159, -2.7814, -2.8248, -1.8489, -2.2972, -2.6274,\n",
            "         -1.7522, -3.0812],\n",
            "        [-1.4937, -2.5326, -2.8869, -2.7164, -3.0411, -1.8526, -2.1765, -3.0826,\n",
            "         -1.6907, -3.6549],\n",
            "        [-1.0286, -1.8305, -2.7267, -2.6249, -3.0407, -2.7063, -2.6212, -3.0474,\n",
            "         -2.4511, -3.7587],\n",
            "        [-1.7817, -2.3933, -2.2672, -2.0056, -2.4649, -2.5283, -2.5017, -3.0320,\n",
            "         -1.9183, -2.8084],\n",
            "        [-1.6918, -2.5532, -2.4759, -2.5634, -2.9845, -2.4113, -1.7615, -2.9303,\n",
            "         -1.6999, -3.5500],\n",
            "        [-1.3970, -2.9027, -3.0109, -2.7588, -2.8065, -1.8040, -2.3524, -3.1825,\n",
            "         -1.5963, -3.8702],\n",
            "        [-1.6555, -2.1607, -2.6563, -3.3828, -2.9172, -2.3626, -2.0310, -3.3336,\n",
            "         -1.4200, -3.4188],\n",
            "        [-1.5099, -2.5381, -2.7717, -3.0232, -2.8067, -2.3978, -2.1205, -3.1659,\n",
            "         -1.4061, -3.4973],\n",
            "        [-1.9179, -2.5749, -2.8861, -3.0558, -2.4741, -1.5930, -2.1365, -2.6145,\n",
            "         -1.8650, -3.2106],\n",
            "        [-2.0844, -2.3211, -2.2727, -2.7550, -2.7497, -1.9680, -2.4604, -2.5216,\n",
            "         -1.5676, -3.4156],\n",
            "        [-2.2098, -2.6888, -2.5945, -2.8728, -3.2586, -1.8139, -1.7113, -3.3439,\n",
            "         -1.3920, -3.6845],\n",
            "        [-1.3857, -2.5273, -3.2456, -2.4909, -2.6904, -1.9170, -2.5426, -3.0647,\n",
            "         -1.7380, -3.4396],\n",
            "        [-1.6459, -2.2735, -2.5767, -2.5416, -2.4410, -2.2542, -2.2328, -2.8750,\n",
            "         -1.9195, -3.0558],\n",
            "        [-2.0714, -2.6400, -2.3626, -2.6288, -2.6452, -1.7831, -2.0857, -2.4950,\n",
            "         -1.8886, -3.2397],\n",
            "        [-1.3840, -2.7658, -2.7817, -2.7973, -2.8232, -2.2847, -2.3372, -3.0471,\n",
            "         -1.4564, -3.6800],\n",
            "        [-1.1315, -2.1259, -2.5640, -3.2176, -2.9574, -2.7644, -2.3175, -3.2916,\n",
            "         -1.8626, -3.3492],\n",
            "        [-1.3914, -2.3720, -3.0861, -2.8268, -3.0865, -2.1053, -2.3101, -3.1091,\n",
            "         -1.5592, -3.4601],\n",
            "        [-1.6587, -2.6683, -2.5356, -2.6945, -2.7800, -2.2377, -2.8492, -2.8729,\n",
            "         -1.3117, -3.1961],\n",
            "        [-1.9834, -2.6582, -2.4707, -2.8580, -3.2847, -2.3048, -1.9131, -3.5409,\n",
            "         -1.1873, -3.4566],\n",
            "        [-1.6881, -2.4920, -2.5813, -3.3207, -2.9062, -2.2076, -2.3462, -3.3356,\n",
            "         -1.2291, -3.4405],\n",
            "        [-2.0270, -2.4005, -2.3664, -2.5335, -2.8091, -2.2113, -2.0363, -2.1789,\n",
            "         -1.8541, -3.3723],\n",
            "        [-1.6447, -2.2736, -2.6204, -3.3205, -2.8346, -2.6662, -2.4737, -3.1246,\n",
            "         -1.2105, -3.2052],\n",
            "        [-1.3788, -2.7475, -3.5349, -2.6025, -3.3590, -2.1307, -1.9335, -1.8416,\n",
            "         -2.2501, -3.9809],\n",
            "        [-1.9119, -2.8902, -2.5057, -2.6544, -2.7944, -1.3802, -2.0141, -3.3179,\n",
            "         -2.0733, -3.3089],\n",
            "        [-1.6226, -2.6679, -2.6282, -3.0649, -3.2998, -2.0860, -1.6266, -3.4274,\n",
            "         -1.6241, -3.6076],\n",
            "        [-1.9826, -2.5362, -2.4075, -2.4640, -2.4173, -1.9349, -2.1758, -2.8794,\n",
            "         -1.8282, -3.1234],\n",
            "        [-2.0160, -2.7897, -2.5170, -2.6535, -2.8492, -1.9325, -2.2702, -2.7282,\n",
            "         -1.3629, -3.6090],\n",
            "        [-1.9758, -2.4822, -2.8875, -2.5965, -2.5563, -1.3839, -2.4013, -3.0611,\n",
            "         -1.8818, -3.5204],\n",
            "        [-1.4534, -2.2142, -2.9405, -2.8408, -2.6535, -2.4611, -2.0822, -2.1508,\n",
            "         -2.1554, -3.4075],\n",
            "        [-1.5782, -2.4298, -2.8117, -2.5921, -2.8788, -2.1396, -2.1554, -3.0484,\n",
            "         -1.6789, -3.0604]], grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([4, 8, 4, 3, 2, 9, 6, 1, 2, 8, 5, 7, 7, 5, 8, 4, 3, 2, 0, 8, 3, 1, 8, 3,\n",
            "        7, 9, 8, 7, 3, 7, 9, 7, 2, 2, 5, 4, 6, 2, 0, 9, 9, 0, 9, 1, 3, 4, 8, 1,\n",
            "        4, 0, 0, 8, 5, 0, 3, 0, 8, 7, 5, 1, 3, 3, 8, 6])\n",
            "Training loss after 2 epochs: 0.000000\n",
            "tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        ...,\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.]])\n",
            "tensor([[-1.3939, -2.7283, -3.0014, -2.8922, -2.7915, -2.5372, -1.9244, -3.0546,\n",
            "         -1.5611, -3.2711],\n",
            "        [-1.5248, -2.3603, -2.6552, -3.1665, -2.7105, -2.6643, -2.0734, -3.3877,\n",
            "         -1.3925, -3.4617],\n",
            "        [-1.5577, -2.2688, -2.3663, -3.7153, -2.6272, -2.5771, -2.3128, -3.4957,\n",
            "         -1.3586, -3.4059],\n",
            "        [-1.1126, -2.7084, -2.5609, -2.7374, -2.8664, -2.2057, -2.6700, -3.7470,\n",
            "         -1.7108, -3.8148],\n",
            "        [-1.7692, -2.3815, -2.8477, -2.9470, -2.6999, -1.9117, -2.3093, -2.7157,\n",
            "         -1.5229, -3.5746],\n",
            "        [-1.1785, -1.9890, -2.5894, -2.9134, -3.1327, -3.3068, -2.3470, -2.8366,\n",
            "         -1.8181, -3.5332],\n",
            "        [-1.3217, -2.8079, -2.9071, -2.4758, -2.6041, -2.4670, -2.3677, -3.2701,\n",
            "         -1.5230, -3.6625],\n",
            "        [-2.3726, -2.4647, -2.4037, -3.4679, -2.8889, -1.9238, -1.8285, -3.4006,\n",
            "         -1.3385, -3.1645],\n",
            "        [-1.5198, -2.3999, -2.8970, -2.5380, -3.2721, -2.1443, -2.0465, -2.4080,\n",
            "         -1.8112, -3.9851],\n",
            "        [-1.4889, -2.3822, -3.0388, -3.0590, -2.9233, -2.3882, -1.6593, -3.3234,\n",
            "         -1.6321, -3.9206],\n",
            "        [-1.9338, -2.4505, -3.0763, -2.9146, -2.9347, -1.4903, -1.8523, -3.1418,\n",
            "         -1.9056, -3.1813],\n",
            "        [-1.6705, -1.9375, -2.4289, -2.3767, -2.6715, -2.3494, -2.2190, -2.5237,\n",
            "         -2.5027, -2.9667],\n",
            "        [-2.2312, -2.5686, -2.4388, -2.7348, -2.5261, -1.5384, -2.2876, -2.8301,\n",
            "         -1.7650, -3.2865],\n",
            "        [-1.3132, -2.5670, -3.0369, -2.8423, -2.9353, -1.6885, -2.4041, -3.0639,\n",
            "         -1.9638, -3.4199],\n",
            "        [-1.8015, -2.4997, -2.4808, -2.8721, -2.7394, -1.9695, -2.2644, -2.8601,\n",
            "         -1.5585, -3.3016],\n",
            "        [-1.5172, -2.1768, -2.8363, -3.0710, -3.1566, -2.4334, -2.3135, -3.0175,\n",
            "         -1.3739, -3.4741],\n",
            "        [-1.5465, -2.9788, -2.6958, -2.7925, -2.9330, -1.9764, -2.2792, -2.9072,\n",
            "         -1.4629, -3.6107],\n",
            "        [-1.2610, -2.6941, -3.0273, -2.8346, -2.9971, -2.3274, -2.0554, -2.3473,\n",
            "         -1.9775, -3.4334],\n",
            "        [-1.9054, -2.7396, -2.7601, -2.5645, -2.8165, -1.5299, -2.4282, -2.9324,\n",
            "         -1.6294, -3.4263],\n",
            "        [-1.5093, -2.5022, -2.5014, -3.2187, -2.8168, -2.7228, -2.0285, -2.8302,\n",
            "         -1.4847, -3.4268],\n",
            "        [-1.5770, -2.6542, -2.6609, -2.9116, -3.1466, -2.1352, -1.9390, -3.1386,\n",
            "         -1.5815, -3.1074],\n",
            "        [-1.2476, -2.9371, -2.9362, -2.4180, -2.9217, -2.3428, -2.0573, -3.2360,\n",
            "         -1.6855, -4.1843],\n",
            "        [-1.2601, -1.7852, -2.7011, -3.2826, -2.6227, -2.5141, -3.0407, -2.9236,\n",
            "         -1.8731, -3.3462],\n",
            "        [-1.6349, -2.6942, -2.7184, -2.7010, -2.7016, -2.2669, -2.0670, -3.1171,\n",
            "         -1.4867, -3.3074],\n",
            "        [-1.6306, -2.5584, -2.6357, -2.7616, -3.1337, -1.8743, -2.2484, -2.8317,\n",
            "         -1.6074, -3.5066],\n",
            "        [-1.5209, -2.7593, -2.5815, -2.7785, -2.6441, -2.3209, -1.9646, -3.0350,\n",
            "         -1.6792, -3.3166],\n",
            "        [-1.2269, -2.5959, -2.6218, -3.0449, -2.6596, -2.6111, -2.2839, -3.0444,\n",
            "         -1.7140, -3.2476],\n",
            "        [-1.8149, -2.2494, -2.3770, -2.5880, -2.9453, -2.1549, -1.9747, -2.4722,\n",
            "         -2.1153, -2.9685],\n",
            "        [-1.6295, -2.4886, -2.4209, -2.8176, -2.6949, -2.3485, -2.5896, -2.2711,\n",
            "         -1.6116, -3.4589],\n",
            "        [-1.7113, -1.6506, -2.4699, -2.7881, -3.0458, -2.3036, -2.6334, -2.9860,\n",
            "         -1.7596, -3.2336],\n",
            "        [-1.7733, -2.3298, -2.5836, -2.5965, -2.5252, -2.0907, -2.1481, -2.9301,\n",
            "         -1.7752, -3.2268],\n",
            "        [-1.3658, -2.4867, -2.6987, -2.5885, -3.1552, -2.3840, -2.2584, -2.2881,\n",
            "         -1.8953, -3.5701],\n",
            "        [-1.3516, -2.1496, -3.0292, -2.8656, -2.9511, -2.2808, -1.8723, -3.1896,\n",
            "         -1.9465, -3.6074],\n",
            "        [-1.3235, -2.5956, -2.7330, -2.8221, -2.3860, -2.0840, -2.1028, -2.9847,\n",
            "         -2.1790, -3.4284],\n",
            "        [-2.0175, -2.5608, -2.3293, -2.7648, -2.7322, -1.7544, -2.1692, -2.6017,\n",
            "         -1.8484, -3.0915],\n",
            "        [-1.6803, -2.6448, -3.1673, -2.5150, -2.8638, -1.7754, -2.3474, -2.3742,\n",
            "         -1.7176, -3.6889],\n",
            "        [-1.5307, -2.9636, -2.9715, -2.8955, -2.5729, -2.2842, -1.8348, -3.2232,\n",
            "         -1.5425, -3.3809],\n",
            "        [-1.9788, -2.5856, -2.7549, -2.6840, -2.6736, -1.6265, -2.1536, -2.9212,\n",
            "         -1.6869, -3.3854],\n",
            "        [-1.4545, -2.2795, -3.3123, -2.7293, -2.5222, -1.7734, -2.4007, -3.3671,\n",
            "         -1.8230, -3.6605],\n",
            "        [-1.2315, -3.0628, -2.9044, -2.8676, -2.9914, -2.1418, -2.4931, -2.8354,\n",
            "         -1.5197, -3.8164],\n",
            "        [-1.8394, -2.2751, -2.7220, -2.5732, -2.4076, -1.9176, -2.0054, -3.3288,\n",
            "         -1.7837, -3.8720],\n",
            "        [-1.5134, -2.5414, -2.8784, -2.7780, -3.0242, -1.7288, -2.4222, -2.8300,\n",
            "         -1.6765, -3.8236],\n",
            "        [-1.6681, -2.6322, -2.7382, -2.5430, -2.5707, -1.9567, -2.0173, -3.0130,\n",
            "         -1.8741, -3.1540],\n",
            "        [-1.5793, -2.4014, -2.6055, -2.6824, -2.3904, -2.3612, -2.8780, -2.2411,\n",
            "         -1.7501, -3.2497],\n",
            "        [-1.9007, -2.7246, -2.7637, -2.9969, -2.8276, -2.5185, -1.2891, -3.0521,\n",
            "         -1.7976, -3.1295],\n",
            "        [-1.7932, -2.4694, -3.2013, -2.7490, -2.9060, -1.7959, -2.0306, -2.9164,\n",
            "         -1.5475, -3.6731],\n",
            "        [-1.5069, -2.2117, -2.9317, -2.6624, -3.1701, -2.3914, -2.0874, -2.5343,\n",
            "         -1.6896, -3.7143],\n",
            "        [-2.1230, -2.6796, -2.3345, -2.6984, -2.7635, -1.6399, -2.1468, -2.6955,\n",
            "         -1.7986, -3.2042],\n",
            "        [-1.6983, -2.7449, -3.0101, -2.5087, -2.7851, -2.1127, -1.8730, -2.7706,\n",
            "         -1.6194, -3.6831],\n",
            "        [-1.9114, -2.3103, -2.4748, -3.0180, -3.1405, -2.0163, -1.6377, -2.7135,\n",
            "         -2.0248, -2.9827],\n",
            "        [-1.4343, -2.1716, -2.3651, -3.1593, -2.6538, -2.5473, -2.6220, -3.2532,\n",
            "         -1.5932, -3.0347],\n",
            "        [-1.8833, -2.6708, -2.9234, -2.6901, -2.9414, -1.4465, -2.4368, -2.9549,\n",
            "         -1.6377, -3.3542],\n",
            "        [-1.6555, -2.1631, -2.2577, -3.1188, -3.1296, -2.5337, -1.8436, -2.8440,\n",
            "         -1.7735, -3.3254],\n",
            "        [-1.1213, -2.8455, -3.3482, -2.3979, -2.9531, -2.5311, -2.4277, -3.0293,\n",
            "         -1.5786, -4.1738],\n",
            "        [-2.1567, -2.5927, -2.7585, -2.5755, -3.1749, -2.0759, -1.4696, -2.8357,\n",
            "         -1.8151, -2.9717],\n",
            "        [-1.9998, -2.3778, -2.2820, -2.9717, -2.8445, -2.1652, -1.5760, -2.5572,\n",
            "         -2.2279, -2.9255],\n",
            "        [-1.3387, -2.4371, -2.3286, -2.7567, -2.5829, -2.7972, -2.4705, -2.5715,\n",
            "         -2.0667, -2.7278],\n",
            "        [-2.0978, -2.6042, -2.6900, -2.3680, -3.0659, -2.2769, -2.0361, -2.4249,\n",
            "         -1.3902, -3.7086],\n",
            "        [-1.9355, -3.1495, -2.9966, -3.1461, -3.0565, -1.7053, -1.5073, -3.3339,\n",
            "         -1.6116, -3.3727],\n",
            "        [-1.8107, -2.9293, -2.7544, -2.5144, -2.9912, -2.2140, -1.4829, -3.0887,\n",
            "         -1.7331, -3.5163],\n",
            "        [-1.2078, -2.8402, -2.7167, -2.6816, -3.1507, -2.3050, -2.5092, -3.4554,\n",
            "         -1.4728, -3.7546],\n",
            "        [-1.0999, -2.9639, -2.5067, -3.3339, -2.7991, -2.7475, -2.4942, -2.8179,\n",
            "         -1.6046, -3.5043],\n",
            "        [-1.5503, -2.5983, -2.8746, -2.5971, -2.4226, -2.0376, -1.8850, -3.3315,\n",
            "         -1.9402, -3.4355],\n",
            "        [-1.1658, -2.7301, -3.4197, -2.6744, -3.2643, -2.4972, -2.1119, -3.5118,\n",
            "         -1.4610, -4.0138]], grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([4, 5, 0, 9, 8, 0, 9, 5, 8, 0, 9, 2, 1, 1, 8, 0, 9, 8, 6, 8, 7, 9, 0, 4,\n",
            "        9, 4, 0, 7, 6, 3, 2, 4, 0, 4, 1, 8, 4, 1, 5, 5, 9, 6, 1, 5, 2, 3, 8, 1,\n",
            "        9, 7, 0, 3, 7, 9, 7, 7, 2, 8, 3, 3, 4, 5, 4, 9])\n",
            "Training loss after 3 epochs: 0.000000\n",
            "tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        ...,\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "        [-1., -1., -1.,  ..., -1., -1., -1.]])\n",
            "tensor([[-1.3704, -2.8884, -2.8983, -2.5631, -3.1212, -2.2030, -2.7018, -2.7179,\n",
            "         -1.3807, -3.9590],\n",
            "        [-2.0895, -2.6171, -2.4629, -2.8558, -3.0222, -1.3039, -2.2273, -2.9882,\n",
            "         -1.9132, -3.3644],\n",
            "        [-2.1446, -2.8080, -1.9875, -2.9324, -3.0510, -2.4008, -2.0815, -2.4318,\n",
            "         -1.4100, -3.2829],\n",
            "        [-1.6362, -2.4999, -3.2395, -2.6950, -2.9349, -1.7839, -1.9736, -2.6894,\n",
            "         -1.8142, -3.6688],\n",
            "        [-1.8369, -2.2858, -2.2702, -2.8961, -2.4550, -2.7501, -2.5340, -3.4497,\n",
            "         -1.2745, -3.2185],\n",
            "        [-1.9651, -2.4658, -2.4880, -2.5929, -2.6427, -2.1564, -1.9091, -3.5077,\n",
            "         -1.4769, -3.7469],\n",
            "        [-1.6691, -2.4035, -2.6127, -2.5812, -2.6946, -2.6402, -2.1872, -3.3870,\n",
            "         -1.3580, -3.5051],\n",
            "        [-1.7756, -2.1140, -2.5568, -2.8859, -3.1532, -2.1846, -1.7647, -2.8494,\n",
            "         -1.8624, -3.3006],\n",
            "        [-2.0246, -2.5715, -2.6320, -2.8769, -2.4857, -1.6779, -2.0203, -3.3977,\n",
            "         -1.6823, -3.1884],\n",
            "        [-1.5426, -2.3024, -2.1208, -2.7962, -3.2161, -2.8228, -1.6915, -2.6839,\n",
            "         -2.1528, -3.2990],\n",
            "        [-2.2520, -2.2915, -2.7075, -2.5966, -3.1305, -2.4897, -1.4213, -2.4759,\n",
            "         -1.7330, -3.7464],\n",
            "        [-1.6466, -2.4900, -2.9826, -2.4657, -3.0632, -1.9324, -1.5806, -2.6588,\n",
            "         -2.5499, -3.1404],\n",
            "        [-0.9779, -2.4445, -2.9772, -2.7182, -3.5732, -2.5347, -2.5382, -2.5148,\n",
            "         -1.9920, -4.1015],\n",
            "        [-1.7951, -2.5022, -2.7362, -2.5729, -3.0829, -1.7495, -2.0703, -2.7691,\n",
            "         -1.7433, -3.5983],\n",
            "        [-1.3353, -2.5185, -2.4465, -3.0597, -3.2848, -2.5014, -2.0244, -3.0195,\n",
            "         -1.7177, -3.1456],\n",
            "        [-1.7790, -2.6316, -2.4068, -2.7499, -2.4962, -2.1564, -1.9009, -2.7950,\n",
            "         -1.8021, -3.4560],\n",
            "        [-2.0582, -2.7200, -2.5385, -2.6193, -2.8333, -1.6747, -1.8850, -2.4290,\n",
            "         -2.0137, -3.3528],\n",
            "        [-1.3700, -2.3854, -2.5648, -2.8097, -2.6023, -2.7765, -2.5657, -2.4241,\n",
            "         -1.7781, -3.0805],\n",
            "        [-1.6679, -2.8557, -2.5089, -2.5179, -2.9721, -1.3978, -2.4527, -3.0808,\n",
            "         -2.0451, -3.4369],\n",
            "        [-1.8186, -2.1091, -2.4293, -2.7402, -2.2880, -2.2652, -2.3690, -2.6084,\n",
            "         -1.8461, -3.3994],\n",
            "        [-1.2835, -2.1170, -2.2098, -3.0106, -2.8030, -2.8860, -2.4767, -2.9278,\n",
            "         -1.8391, -3.4856],\n",
            "        [-1.4662, -2.5297, -2.8967, -2.8224, -3.0397, -1.9447, -2.2390, -2.7171,\n",
            "         -1.7041, -3.5268],\n",
            "        [-1.4615, -2.6324, -3.2593, -2.5182, -2.8370, -1.8132, -2.1116, -2.8635,\n",
            "         -1.8881, -3.6508],\n",
            "        [-1.4945, -2.8284, -2.5932, -2.6517, -3.3191, -1.7943, -2.2714, -3.0270,\n",
            "         -1.6364, -3.7952],\n",
            "        [-1.4631, -2.6411, -3.1826, -2.5171, -2.7147, -1.9582, -1.6616, -2.7767,\n",
            "         -2.4286, -3.5961],\n",
            "        [-1.5503, -2.5983, -2.8746, -2.5971, -2.4226, -2.0376, -1.8850, -3.3315,\n",
            "         -1.9402, -3.4355],\n",
            "        [-1.9956, -2.1827, -2.8684, -2.9707, -3.0125, -2.3656, -1.8884, -3.0589,\n",
            "         -1.3259, -3.3130],\n",
            "        [-1.5267, -2.4356, -3.0396, -3.1783, -2.1693, -3.1567, -2.5169, -3.0916,\n",
            "         -1.2347, -3.4481],\n",
            "        [-2.0695, -2.4203, -2.4404, -2.6252, -2.5570, -1.9565, -1.9675, -3.1204,\n",
            "         -1.7980, -2.8674],\n",
            "        [-1.5791, -2.0833, -2.5432, -2.8794, -2.6879, -3.1298, -2.6226, -3.4118,\n",
            "         -1.2462, -3.5204],\n",
            "        [-1.7619, -2.0745, -2.7165, -2.6388, -2.7058, -2.3887, -2.4909, -2.6021,\n",
            "         -1.5446, -3.3186],\n",
            "        [-1.7676, -2.5787, -2.4286, -2.5683, -2.5274, -2.2988, -2.1603, -2.7237,\n",
            "         -1.7674, -2.8712],\n",
            "        [-1.6298, -2.9544, -3.0261, -2.5862, -2.9595, -1.7960, -2.0350, -1.9746,\n",
            "         -2.2117, -3.4645],\n",
            "        [-1.4829, -1.9106, -2.5338, -3.1063, -2.5521, -2.4746, -2.6583, -3.0498,\n",
            "         -1.8472, -2.7539],\n",
            "        [-2.0967, -2.4855, -2.1717, -2.8871, -2.7359, -1.7389, -2.4975, -2.6891,\n",
            "         -1.6533, -3.1712],\n",
            "        [-1.5600, -2.4532, -2.9671, -2.6297, -2.9674, -1.9564, -2.1856, -2.8846,\n",
            "         -1.6586, -3.5478],\n",
            "        [-1.4004, -2.5993, -2.9240, -2.8329, -2.7417, -1.8319, -2.3232, -3.0832,\n",
            "         -1.8096, -3.3648],\n",
            "        [-1.5703, -2.2286, -2.3504, -3.3113, -3.0914, -2.5795, -1.8023, -3.3930,\n",
            "         -1.5744, -3.6643],\n",
            "        [-1.9960, -2.5675, -2.6886, -2.6320, -2.4852, -1.7139, -2.2941, -3.0791,\n",
            "         -1.6514, -3.0922],\n",
            "        [-1.4874, -2.9661, -3.1769, -2.3472, -2.7496, -2.0218, -2.1407, -2.6912,\n",
            "         -1.7489, -3.5240],\n",
            "        [-1.4962, -2.4812, -3.1817, -2.9363, -2.8191, -2.3925, -1.8435, -3.2589,\n",
            "         -1.4718, -3.8868],\n",
            "        [-1.9209, -2.4518, -2.2767, -2.5300, -3.0670, -2.4421, -1.7209, -3.0142,\n",
            "         -1.7627, -2.9563],\n",
            "        [-1.6156, -2.7196, -2.6386, -2.9843, -2.7839, -2.0627, -2.1230, -2.7278,\n",
            "         -1.5800, -3.4001],\n",
            "        [-1.7360, -2.4080, -2.9992, -2.7525, -2.9659, -1.8810, -1.4802, -2.7211,\n",
            "         -2.3434, -3.6182],\n",
            "        [-1.6473, -2.5179, -2.6622, -2.6256, -3.2920, -2.3306, -1.6400, -2.7019,\n",
            "         -1.7610, -4.0595],\n",
            "        [-1.5583, -2.3682, -3.0109, -2.9830, -2.5728, -2.3151, -1.7481, -2.7817,\n",
            "         -1.8754, -3.4555],\n",
            "        [-1.5560, -2.2947, -2.1263, -3.2132, -2.8786, -2.5979, -2.6193, -3.4584,\n",
            "         -1.4788, -2.7204],\n",
            "        [-1.1840, -2.1535, -3.6288, -2.4795, -3.0199, -2.5345, -1.7469, -2.8715,\n",
            "         -2.4919, -3.6596],\n",
            "        [-2.0750, -2.5002, -2.2337, -2.7342, -2.8671, -1.7243, -2.2287, -2.6446,\n",
            "         -1.7736, -3.3047],\n",
            "        [-1.5207, -2.3636, -3.2271, -2.6574, -2.9279, -2.4126, -1.8549, -2.7196,\n",
            "         -1.7950, -3.0800],\n",
            "        [-1.9355, -2.6376, -2.5640, -2.7611, -2.6474, -1.8324, -1.9674, -2.7578,\n",
            "         -1.7735, -3.2178],\n",
            "        [-1.6509, -2.3248, -2.7402, -2.6111, -2.8749, -2.3300, -1.7021, -3.0695,\n",
            "         -1.8167, -3.6016],\n",
            "        [-2.1495, -2.9652, -3.0571, -2.6577, -2.4941, -1.7027, -1.8454, -2.7058,\n",
            "         -1.6620, -3.3389],\n",
            "        [-1.6210, -2.2292, -2.4024, -2.8025, -3.1356, -2.2633, -2.2252, -2.7280,\n",
            "         -1.6786, -3.3242],\n",
            "        [-1.7979, -2.0437, -2.9297, -2.6167, -3.2528, -2.3842, -2.0953, -2.4266,\n",
            "         -1.5805, -3.4974],\n",
            "        [-1.6728, -2.5671, -2.4993, -2.7490, -2.5651, -2.0120, -2.2147, -2.9160,\n",
            "         -1.7188, -3.3205],\n",
            "        [-1.9919, -2.7589, -3.1829, -2.6448, -3.2007, -1.8682, -1.7601, -1.9696,\n",
            "         -1.8640, -3.6494],\n",
            "        [-1.0741, -2.3437, -3.1533, -2.2883, -2.8101, -2.8252, -2.0094, -3.3448,\n",
            "         -2.2454, -3.7485],\n",
            "        [-1.3907, -2.6123, -2.7271, -3.5268, -2.7623, -2.1784, -1.9067, -2.5233,\n",
            "         -1.8869, -3.6404],\n",
            "        [-1.8731, -1.9649, -2.3941, -2.6747, -2.6053, -2.5337, -2.4346, -3.2939,\n",
            "         -1.5317, -2.9590],\n",
            "        [-2.0190, -2.3601, -2.1804, -2.6490, -2.6143, -1.8014, -2.1997, -2.6723,\n",
            "         -2.0536, -3.1553],\n",
            "        [-1.7058, -3.0149, -2.5638, -2.8905, -2.9452, -2.2682, -1.7143, -2.6776,\n",
            "         -1.6437, -3.2551],\n",
            "        [-1.5347, -2.4513, -2.4810, -2.6626, -2.8488, -2.2620, -2.0942, -2.8495,\n",
            "         -1.8828, -3.0035],\n",
            "        [-1.3414, -2.4450, -2.7590, -2.5906, -3.0745, -2.1778, -2.0550, -2.8783,\n",
            "         -1.9933, -3.3991]], grad_fn=<LogSoftmaxBackward>)\n",
            "tensor([8, 7, 0, 3, 8, 0, 9, 9, 4, 0, 8, 6, 8, 3, 9, 7, 2, 3, 7, 4, 8, 5, 9, 7,\n",
            "        6, 4, 8, 8, 8, 8, 8, 2, 8, 6, 1, 6, 1, 0, 1, 9, 5, 2, 5, 8, 3, 7, 6, 6,\n",
            "        1, 6, 1, 9, 8, 2, 8, 1, 8, 6, 5, 2, 1, 1, 3, 6])\n",
            "Training loss after 4 epochs: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdKm9J5GNYCx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "2aea4f70-3213-4b12-e969-9bebb84b20b5"
      },
      "source": [
        "plt.plot(my_LR.loss_during_training,'-b',label='Cross Entropy Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAx0AAAILCAYAAACNYfGhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1FX/HwGEKniyjHpGAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 398,
              "height": 261
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWWXa75gNYC2"
      },
      "source": [
        "To evaluate the performance across the entire test dataset, we will implement a for loop using `testloader` and compute errors per mini-batch. The following code will do the work:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4KLhDVONYC4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7d26b9c-d4e5-4269-9699-7bd21ee2ce92"
      },
      "source": [
        "loss = 0\n",
        "accuracy = 0\n",
        "\n",
        "# Turn off gradients for validation, saves memory and computations\n",
        "with torch.no_grad():\n",
        "\n",
        "    for images,labels in testloader:\n",
        "        \n",
        "        probs = my_LR.forward(images.view(images.shape[0], -1))\n",
        "        \n",
        "        top_p, top_class = probs.topk(1, dim=1)\n",
        "        equals = (top_class == labels.view(images.shape[0], 1)) \n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor)) #num de etiquetas que aciertas por cada minibatch\n",
        "    \n",
        "\n",
        "print(\"Test Accuracy %f\" %(accuracy/len(testloader)))  #num de etiquetas que aciertas en total "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy 0.918292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y7fzfqUNYC9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c073ca3d-ab20-44f8-d8b8-6bf77252126e"
      },
      "source": [
        "top_class.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMY-3hiWNYDD"
      },
      "source": [
        "With the probabilities, we can get the most likely class using the `probs.topk` method. This returns the $k$ highest values. Since we just want the most likely class, we can use `probs.topk(1)`. This returns a tuple of the top-$k$ values and the top-$k$ indices. If the highest value is the fifth element, we'll get back 4 as the index.\n",
        "\n",
        "The line \n",
        "```python\n",
        "(top_class == labels.view(images.shape[0], 1))\n",
        "```\n",
        "returns a boolean vector of `True/False` values, indicanting werther `top_class` is equeal to `labels` at every position. Finally, with the line\n",
        "\n",
        "```python\n",
        "equals.type(torch.FloatTensor)\n",
        "```\n",
        "we transform it to real a vector in which `True --> 1.0` and `False --> 0.0`, where we can compute the mean using `torch.mean()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zznb89lPNYDF"
      },
      "source": [
        "> **Excercise** Modify the code of the `Multi_LR_extended` class so it incorporates a method to evaluate the performance in either the train set or the test set (Use a single method with the proper inputs!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zMwEUFJNYDG"
      },
      "source": [
        "''' This class inherits from the `Multi_LR` class. So it has the same atributes\n",
        "and methods, and some others that we will add. \n",
        "'''\n",
        "class Multi_LR_extended2(Multi_LR):\n",
        "    \n",
        "    #Your code here\n",
        "    \n",
        "    def __init__(self,dimx,nlabels,epochs=100,lr=0.001):\n",
        "        \n",
        "        # Your code here  \n",
        "        super().__init__(dimx,nlabels)  #To initialize `Multi_LR`!\n",
        "        \n",
        "        self.lr = lr #Learning Rate\n",
        "        \n",
        "        self.optim = optim.Adam(self.parameters(), self.lr)\n",
        "        \n",
        "        self.epochs = epochs\n",
        "        \n",
        "        self.criterion = nn.NLLLoss()               # NEW w.r.t Lab 1\n",
        "        \n",
        "        # A list to store the loss evolution along training\n",
        "        \n",
        "        self.loss_during_training = [] \n",
        "        \n",
        "    def train(self,trainloader):\n",
        "        \n",
        "         # Optimization Loop\n",
        "        \n",
        "        for e in range(int(self.epochs)):\n",
        "            \n",
        "            # Random data permutation at each epoch\n",
        "            \n",
        "            running_loss = 0.\n",
        "            \n",
        "            for images, labels in trainloader:              # NEW w.r.t Lab 1\n",
        "        \n",
        "                self.optim.zero_grad()  #TO RESET GRADIENTS!\n",
        "            \n",
        "                out = self.forward(images.view(images.shape[0], -1))\n",
        "\n",
        "                loss = self.criterion(out,labels)\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                \n",
        "                #Your code here\n",
        "                loss.backward()\n",
        "                self.optim.step()\n",
        "                \n",
        "            self.loss_during_training.append(running_loss/len(trainloader))\n",
        "\n",
        "            if(e % 1 == 0): # Every 10 epochs\n",
        "\n",
        "                print(\"Training loss after %d epochs: %f\" \n",
        "                      %(e,self.loss_during_training[-1]))\n",
        "\n",
        "    def eval_performance(self,dataloader):\n",
        "           \n",
        "        loss = 0\n",
        "        accuracy = 0\n",
        "\n",
        "        # Turn off gradients for validation, saves memory and computations\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for images,labels in dataloader:\n",
        "\n",
        "                # Your code here\n",
        "                probs = self.forward(images.view(images.shape[0], -1))\n",
        "                top_p, top_class = probs.topk(1, dim=1)\n",
        "                equals = (top_class == labels.view(images.shape[0], 1)) \n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "    \n",
        "            return accuracy/len(dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeNG6A6KNYDM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "1649f6fc-7a80-477e-a6e3-e1b7880d90ef"
      },
      "source": [
        "my_LR = Multi_LR_extended2(dimx=784,nlabels=10,epochs=10,lr=1e-3)\n",
        "\n",
        "my_LR.train(trainloader)\n",
        "\n",
        "train_performance = my_LR.eval_performance(trainloader)\n",
        "\n",
        "test_performance = my_LR.eval_performance(testloader)\n",
        "\n",
        "print(\"Train Accuracy %f\" %(train_performance))\n",
        "\n",
        "print(\"Test Accuracy %f\" %(test_performance))\n",
        "\n",
        "#esta biased porque practicamente da lo mismo en test y train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss after 0 epochs: 0.474461\n",
            "Training loss after 1 epochs: 0.327601\n",
            "Training loss after 2 epochs: 0.310078\n",
            "Training loss after 3 epochs: 0.302175\n",
            "Training loss after 4 epochs: 0.294072\n",
            "Training loss after 5 epochs: 0.291264\n",
            "Training loss after 6 epochs: 0.287256\n",
            "Training loss after 7 epochs: 0.283830\n",
            "Training loss after 8 epochs: 0.282859\n",
            "Training loss after 9 epochs: 0.279486\n",
            "Train Accuracy 0.927322\n",
            "Test Accuracy 0.924562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvQEWekDNYDR"
      },
      "source": [
        "Observe that both values are indeed similar, indicating that the model is **biased**. \n",
        "\n",
        "Let's check the values for the weight matrix. For a simpler visualization, we will plot the histogram of all the values in the weight matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "a3dd5Nd-NYDS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "outputId": "87e6ab27-d282-460c-dc29-2c302b49100e"
      },
      "source": [
        "plt.hist(my_LR.output.weight.detach().numpy().reshape([-1,]),50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.00e+00, 1.00e+00, 4.00e+00, 3.00e+00, 4.00e+00, 2.00e+00,\n",
              "        8.00e+00, 1.10e+01, 8.00e+00, 1.10e+01, 1.70e+01, 3.10e+01,\n",
              "        3.00e+01, 6.40e+01, 7.10e+01, 1.02e+02, 1.51e+02, 1.55e+02,\n",
              "        2.39e+02, 2.99e+02, 5.55e+02, 8.34e+02, 1.04e+03, 1.10e+03,\n",
              "        8.88e+02, 6.23e+02, 4.09e+02, 2.94e+02, 2.29e+02, 1.82e+02,\n",
              "        1.54e+02, 1.04e+02, 8.40e+01, 4.20e+01, 3.00e+01, 1.50e+01,\n",
              "        1.40e+01, 6.00e+00, 1.10e+01, 2.00e+00, 3.00e+00, 3.00e+00,\n",
              "        0.00e+00, 3.00e+00, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
              "        1.00e+00, 1.00e+00]),\n",
              " array([-0.5256403 , -0.50302154, -0.48040274, -0.45778394, -0.43516514,\n",
              "        -0.41254637, -0.38992757, -0.3673088 , -0.34469   , -0.3220712 ,\n",
              "        -0.29945242, -0.27683362, -0.25421482, -0.23159604, -0.20897725,\n",
              "        -0.18635847, -0.16373968, -0.14112088, -0.1185021 , -0.0958833 ,\n",
              "        -0.07326452, -0.05064572, -0.02802694, -0.00540815,  0.01721064,\n",
              "         0.03982943,  0.06244822,  0.08506701,  0.1076858 ,  0.13030459,\n",
              "         0.15292338,  0.17554218,  0.19816096,  0.22077975,  0.24339855,\n",
              "         0.26601732,  0.28863612,  0.31125492,  0.3338737 ,  0.3564925 ,\n",
              "         0.3791113 ,  0.40173006,  0.42434886,  0.44696766,  0.46958643,\n",
              "         0.49220523,  0.51482403,  0.5374428 ,  0.5600616 ,  0.5826804 ,\n",
              "         0.6052992 ], dtype=float32),\n",
              " <a list of 50 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvsAAAHwCAYAAAA4rqAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwj4AAHRK2AcAgE79/313SrxEqxOxAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 381,
              "height": 248
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHeV51a7NYDW"
      },
      "source": [
        "## Part III. Train a MLP to do the same job\n",
        "\n",
        "Modify the code you have just implemented for a MLP is straightforward. Assume we want to train a MLP with three layers, all using rectified linear units (RELU)s as non-linear activations (except the last layer, that uses a Softmax). The first layer has 128 hidden units and the second 64 of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1cbwCifNYDY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "71e6d607-9e68-4b51-8d3c-cdbb78214a89"
      },
      "source": [
        "Image(url= \"https://pytorch.org/docs/stable/_images/ReLU.png\", width=600, height=300)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://pytorch.org/docs/stable/_images/ReLU.png\" width=\"600\" height=\"300\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "395Q04p9NYDc"
      },
      "source": [
        "As with the LR, we create a small class defining the model and then a larger class than inherites from it to incorporate methods to perform both training and model evaluation.\n",
        "\n",
        "> **Exercise**: Complete the code for the following class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df49CR1CNYDe"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self,dimx,hidden1,hidden2,nlabels): #Nlabels will be 10 in our case\n",
        "        super().__init__()\n",
        "        \n",
        "        self.output1 = nn.Linear(dimx,hidden1)\n",
        "        \n",
        "        self.output2 = nn.Linear(hidden1,hidden2)\n",
        "        \n",
        "        self.output3 = nn.Linear(hidden2,nlabels)\n",
        "    \n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)                                                             \n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Pass the input tensor through each of our operations\n",
        "        \n",
        "        #YOUR CODE HERE\n",
        "        x=self.output1(x)\n",
        "        x=self.relu(x)\n",
        "        x=self.output2(x)\n",
        "        x=self.relu(x)\n",
        "        x=self.output3(x)\n",
        "        x=self.logsoftmax(x)\n",
        "        \n",
        "        \n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soYh77eXNYDl"
      },
      "source": [
        "> **Excercise** Create a class `MLP_extended` that incorporates two methods to the former class. One to perform training and one to perform model evaluation. It is just **one line of code** diferent from the code you have done above for the multi-class LR. This is why I like class and structure my code this way!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-0HWvoqNYDq"
      },
      "source": [
        "''' This class inherits from the `Multi_LR` class. So it has the same atributes\n",
        "and methods, and some others that we will add. \n",
        "'''\n",
        "class MLP_extended(MLP):\n",
        "    \n",
        "    \n",
        "    def __init__(self,dimx,hidden1,hidden2,nlabels,epochs=100,lr=0.001):\n",
        "\n",
        "        # Your code here\n",
        "          \n",
        "        super().__init__(dimx,hidden1,hidden2,nlabels)  #To initialize `Multi_LR`!\n",
        "        \n",
        "        self.lr = lr #Learning Rate\n",
        "        \n",
        "        self.optim = optim.Adam(self.parameters(), self.lr)\n",
        "        \n",
        "        self.epochs = epochs\n",
        "        \n",
        "        self.criterion = nn.NLLLoss()               # NEW w.r.t Lab 1\n",
        "        \n",
        "        # A list to store the loss evolution along training\n",
        "        \n",
        "        self.loss_during_training = [] \n",
        "        \n",
        "    def train(self,trainloader):\n",
        "        \n",
        "        # Your code here\n",
        "        # Optimization Loop\n",
        "        \n",
        "        for e in range(int(self.epochs)):\n",
        "            \n",
        "            # Random data permutation at each epoch\n",
        "            \n",
        "            running_loss = 0.\n",
        "            \n",
        "            for images, labels in trainloader:              # NEW w.r.t Lab 1\n",
        "        \n",
        "                self.optim.zero_grad()  #TO RESET GRADIENTS!\n",
        "            \n",
        "                out = self.forward(images.view(images.shape[0], -1))\n",
        "\n",
        "                loss = self.criterion(out,labels)\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                \n",
        "                #Your code here\n",
        "                loss.backward()\n",
        "                self.optim.step()\n",
        "                \n",
        "            self.loss_during_training.append(running_loss/len(trainloader))\n",
        "\n",
        "            if(e % 1 == 0): # Every 10 epochs\n",
        "\n",
        "                print(\"Training loss after %d epochs: %f\" \n",
        "                      %(e,self.loss_during_training[-1]))\n",
        "\n",
        "    def eval_performance(self,dataloader):\n",
        "        \n",
        "        # Your code here\n",
        "        loss = 0\n",
        "        accuracy = 0\n",
        "\n",
        "        # Turn off gradients for validation, saves memory and computations\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for images,labels in dataloader:\n",
        "\n",
        "                # Your code here\n",
        "                probs = my_MLP.forward(images.view(images.shape[0], -1))\n",
        "                top_p, top_class = probs.topk(1, dim=1)\n",
        "                equals = (top_class == labels.view(images.shape[0], 1)) \n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "    \n",
        "            return accuracy/len(dataloader)\n",
        "       \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08mfZVFoNYD2"
      },
      "source": [
        "Train the model for 10 epochs and compute the train/test performance. How does it compare with the Logistic Regressor?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRzHhNPoNYD4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "84f00642-f2d9-4a0b-b864-ee99e9e8cbff"
      },
      "source": [
        "my_MLP = MLP_extended(dimx=784,hidden1=128,hidden2=64,nlabels=10,epochs=10,lr=1e-3)\n",
        "\n",
        "my_MLP.train(trainloader)\n",
        "\n",
        "train_performance = my_MLP.eval_performance(trainloader)\n",
        "\n",
        "test_performance = my_MLP.eval_performance(testloader)\n",
        "\n",
        "print(\"Train Accuracy %f\" %(train_performance))\n",
        "\n",
        "print(\"Test Accuracy %f\" %(test_performance))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss after 0 epochs: 0.404954\n",
            "Training loss after 1 epochs: 0.191766\n",
            "Training loss after 2 epochs: 0.141583\n",
            "Training loss after 3 epochs: 0.115771\n",
            "Training loss after 4 epochs: 0.099153\n",
            "Training loss after 5 epochs: 0.087587\n",
            "Training loss after 6 epochs: 0.078346\n",
            "Training loss after 7 epochs: 0.071441\n",
            "Training loss after 8 epochs: 0.065962\n",
            "Training loss after 9 epochs: 0.057610\n",
            "Train Accuracy 0.985274\n",
            "Test Accuracy 0.972731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDWX5dYiNYD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa458cfa-a357-402a-bd1c-007b19eec5f3"
      },
      "source": [
        "plt.plot(my_MLP.loss_during_training,'-b',label='Cross Entropy Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAAILCAYAAAB4n3oRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHrkTfCntRmMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 392,
              "height": 261
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83QM4s8DNYEB"
      },
      "source": [
        "Wow! Performace is almost perfect with a naive Neural Network!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcM5oho6NYED"
      },
      "source": [
        "### Part IV. Saving and restoring the model\n",
        "\n",
        "Finally, we will show you how to save and load models (i.e. values of the parameters) with PyTorch. This is important because you'll often want to load previously trained models to use in making predictions or to continue training on new data.\n",
        "\n",
        "As you can imagine, it's impractical to train a network every time you need to use it. Instead, we can save trained networks then load them later to train more or use them for predictions.\n",
        "\n",
        "The parameters for PyTorch networks are stored in a model's `state_dict`. We can see the state dict contains the weight and bias matrices for each of our layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9Cz23HiNYEG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d58e804-9b2c-4d5a-d9f0-888cb00612ca"
      },
      "source": [
        "print(\"Our model: \\n\\n\", my_MLP, '\\n')\n",
        "print(\"The state dict keys: \\n\\n\", my_MLP.state_dict().keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our model: \n",
            "\n",
            " MLP_extended(\n",
            "  (output1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (output2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (output3): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (logsoftmax): LogSoftmax()\n",
            "  (criterion): NLLLoss()\n",
            ") \n",
            "\n",
            "The state dict keys: \n",
            "\n",
            " odict_keys(['output1.weight', 'output1.bias', 'output2.weight', 'output2.bias', 'output3.weight', 'output3.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVVyLDKiNYEJ"
      },
      "source": [
        "The simplest thing to do is simply save the state dict with `torch.save`. For example, we can save it to a file `'checkpoint.pth'`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO5iLZ7pNYEK"
      },
      "source": [
        "torch.save(my_MLP.state_dict(), 'checkpoint.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOzmf4iaNYEP"
      },
      "source": [
        "Then we can load the state dict with `torch.load`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEeiCpqjNYET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d9e651-3711-460b-ef9d-627a1166431c"
      },
      "source": [
        "state_dict = torch.load('checkpoint.pth')\n",
        "print(state_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "odict_keys(['output1.weight', 'output1.bias', 'output2.weight', 'output2.bias', 'output3.weight', 'output3.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0eJ17b9NYEW"
      },
      "source": [
        "And to load the state dict in to the network, you do `my_MLP.load_state_dict(state_dict)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqfR2qMuNYEY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8b3d7a9-acec-48e7-e648-ddd4f43447aa"
      },
      "source": [
        "my_MLP.load_state_dict(state_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFfZg9fKNYEd"
      },
      "source": [
        "**Important:** `load_state_dict` will raise an error if the architecture of the network is different from the one saved in the pth file. For example, if we define the following model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0o0O_3uNYEf"
      },
      "source": [
        "my_MLP2 = MLP_extended(dimx=784,hidden1=256,hidden2=128,nlabels=10,epochs=10,lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd2UIY8uNYEl"
      },
      "source": [
        "which differs from `my_MLP` in the dimension of the hidden layers, we will get an error if we call the method  `load_state_dict(state_dict)`.\n",
        "\n",
        "> **Exercise:** Check that you get an error when trying to initialize my_MLP2 from `state_dict` using the method `load_state_dict`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w5HbMpGNYEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "372d0632-3540-4bea-8976-4ec2bd0931ff"
      },
      "source": [
        "#Your code here\n",
        "my_MLP2.load_state_dict(state_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-35e3a694eaab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_MLP2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 839\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MLP_extended:\n\tsize mismatch for output1.weight: copying a param with shape torch.Size([128, 784]) from checkpoint, the shape in current model is torch.Size([256, 784]).\n\tsize mismatch for output1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for output2.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 256]).\n\tsize mismatch for output2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for output3.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128])."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpGDvr2qNYEt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72H82yKwNYEx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}